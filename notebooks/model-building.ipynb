{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statementes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local application imports\n",
    "import sys\n",
    "# import src.utils\n",
    "sys.path.append('../')\n",
    "# import importlib\n",
    "# importlib.reload(src.utils)\n",
    "\n",
    "# Standard library imports\n",
    "from src.utils import SaveModelMetrics\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Other settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Small Group Dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the fields from the datasets that we want\n",
    "\n",
    "- Census Data\n",
    "  - census_carrier_name\n",
    "  - plan_admin_name\n",
    "- Ideon Data\n",
    "  - id\n",
    "  - carrier_name\n",
    "  - name\n",
    "  - plan_type\n",
    "  - level\n",
    "  - primary_care_physician\n",
    "  - network_name\n",
    "  - coinsurance\n",
    "  - issuer_plan_code\n",
    "  - hsa_eligible\n",
    "  - individual_medical_deductible\n",
    "- Evaluation Class\n",
    "  - is_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_group_df_raw = pd.read_csv(\n",
    "    '~/match-plans/data/small_group_dataset.csv', index_col=False)\n",
    "\n",
    "full_df = small_group_df_raw[['id', 'census_carrier_name', 'plan_admin_name', 'carrier_name', 'name', 'plan_type', 'level',\n",
    "                          'primary_care_physician', 'network_name', 'coinsurance', 'issuer_plan_code', 'hsa_eligible', 'individual_medical_deductible', 'is_match']].copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model is meant to be extremely simple; take the information from the census and take the information from ideon that defines carriers and plan name, and jam it together in a text embedding\n",
    "- Let us see how far we can get without any sort of feature engineering at all\n",
    "- We aren't going to do much hyperparameter tuning on this model, just a few folds and a few parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive df\n",
    "naive_df = full_df[['census_carrier_name', 'carrier_name',\n",
    "                    'plan_admin_name', 'name', 'is_match']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the text columns into a single string\n",
    "naive_df['text'] = naive_df['census_carrier_name'] + ' ' + naive_df['carrier_name'] + \\\n",
    "    ' ' + naive_df['plan_admin_name'] + ' ' + naive_df['name']\n",
    "\n",
    "# Create a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "# Fitting the model and transforming the data\n",
    "X = vectorizer.fit_transform(naive_df['text']).toarray()\n",
    "y = naive_df['is_match']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters found: ', grid.best_params_)\n",
    "print('All parameters: ', grid.best_estimator_.get_params())\n",
    "\n",
    "# Use the best model to make predictions\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "SaveModelMetrics(file_path='~/match-plans/data/model_results.csv').save_metrics(\n",
    "    name='naive_model',\n",
    "    description='A naive model that only concantenates the census information and matching ideon information to try and predict is_match using text embeddings',\n",
    "    algorithm='XGBoostClassifier',\n",
    "    best_params_grid_search=grid.best_params_,\n",
    "    params=grid.best_estimator_.get_params(),\n",
    "    accuracy_score=accuracy,\n",
    "    precision_score=precision,\n",
    "    recall=recall,\n",
    "    f1_score=f1,\n",
    "    conf_matrix=conf_matrix\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan Level & Carrier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model will take the niave model, but aim to make it better by feature engineering\n",
    "\n",
    "1. Data Cleaning:\n",
    "    * perform a bunch of data cleaning on the plan_admin_name and census_carrier_name to make comparison easier\n",
    "2. Feature Engineering\n",
    "    * cosine similarity between name and census_plan_admin_name_cleaned\n",
    "    * length of each as a feature\n",
    "    * census_carrier_name_cleaned and carrier_name cosine similarity\n",
    "    * length of each as a feature\n",
    "    * extract plan_type where available in plan_admin_name_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df = full_df[['id','census_carrier_name','plan_admin_name','carrier_name','name','plan_type','level','hsa_eligible','is_match']].copy()\n",
    "df.rename(columns={'plan_admin_name':'census_plan_admin_name','carrier_name':'ideon_carrier_name','name':'ideon_name','plan_type':'ideon_plan_type','level':'ideon_plan_level','hsa_eligible':'ideon_hsa_hdhp'},inplace=True)\n",
    "\n",
    "# set up the cleaned column for plan_admin_name and census_carrier_name\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name']\n",
    "\n",
    "# Remove any capital letter followed by ')' or ':' at the beginning of the string followed by any whitespace - ex: A) or A: or B)\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace('^([A-Z]\\\\))\\\\s*|^([A-Z]\\\\:)\\\\s*', '', regex=True)\n",
    "\n",
    "# in a similar way that we want to remove A) or anything, lets also remove numbers 1. or 2.\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace(\n",
    "    r'\\b\\d{1,2}\\.\\s', \n",
    "    '', \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# lets remove anything contained in () or [] that is not an issuer_code. In other words, if it does not match [XXXX] or (XXXX), then lets remove the [] or if left\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace(\n",
    "    r'\\(([^)]*)\\)|\\[([^\\]]*)\\]|“([^”]*)”|\\\"([^\\\"]*)\\\"', \n",
    "    lambda x: x.group(0) if re.search(\n",
    "        r'\\([A-Z0-9]{2}-[A-Z0-9]{2}\\)|\\[A-Z0-9]{2}-[A-Z0-9]{2}\\]|\\([A-Z0-9]{4}\\)|\\[A-Z0-9]{4}\\]|“[A-Z0-9]{2}-[A-Z0-9]{2}”|\"[A-Z0-9]{2}-[A-Z0-9]{2}\"|“[A-Z0-9]{4}”|\"[A-Z0-9]{4}\"', \n",
    "        x.group(0)\n",
    "    ) \n",
    "    else '', \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# remove any weird characters after cleaning up a bunch - :, (, ), *, !, \", '\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace('[!*“”\":()]+', '', regex=True)\n",
    "\n",
    "# remove any occurrence of '(BASE)', '(Base)', or '(base)', as well as any standalone 'BASE', 'Base', or 'base'\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace('\\\\(BASE\\\\)|\\\\(Base\\\\)|\\\\(base\\\\)|\\\\bBASE\\\\b|\\\\bBase\\\\b|\\\\bbase\\\\b', '', regex=True).str.strip()\n",
    "\n",
    "# remove the YYYY or YY-YY at the beginning of the string with a whitespace after, but be careful of XX-XX and XXXX and other numbers as those are valuable\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace(\n",
    "    r'^(?:\\d{4}|\\d{2}-\\d{2}|\\d{2})\\s+', \n",
    "    '', \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# remove a plan_id if it is somehow in the string\n",
    "df['census_plan_admin_name_cleaned'] = df['census_plan_admin_name_cleaned'].str.replace(r'\\s*-\\s*[0-9A-Z]{14,17}', '', regex=True)\n",
    "\n",
    "# cleaning the census carrier name\n",
    "df['census_carrier_name_cleaned'] = df['census_carrier_name']\n",
    "\n",
    "df['census_carrier_name_cleaned'] = df['census_carrier_name_cleaned'].str.lower().replace({\n",
    "    '.*anthem.*': 'Anthem',\n",
    "    '.*choice.*': 'CalChoice',\n",
    "    '.*medi.*': 'Medi-Excel',\n",
    "    '.*cigna.*': 'Cigna + Oscar',\n",
    "    '.*kaiser.*': 'Kaiser Permanente',\n",
    "    '.*shield.*': 'BlueShield of California',\n",
    "    '.*sutter.*': 'Sutter Health Plus',\n",
    "    '.*covered.*': 'CoveredCA',\n",
    "    '.*united.*': 'UnitedHealthcare',\n",
    "    '.*uhc.*': 'UnitedHealthcare',\n",
    "    '.*Western.*': 'Western Health Advantage',\n",
    "    '.*sharp.*': 'Sharp Health Plan',\n",
    "    '.*aetna.*': 'Aetna',\n",
    "    '.*net.*': 'Health Net',\n",
    "    '.*chinese.*': 'Chinese Community Health Plan'\n",
    "}, regex=True)\n",
    "\n",
    "# drop the old columns\n",
    "df.drop(labels=['census_plan_admin_name','census_carrier_name'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrier Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate length of 'census_carrier_name_cleaned' and 'carrier_name'\n",
    "df['census_carrier_name_length'] = df['census_carrier_name_cleaned'].apply(len)\n",
    "df['ideon_carrier_name_length'] = df['ideon_carrier_name'].apply(len)\n",
    "\n",
    "# 2. Create text embeddings for 'census_carrier_name_cleaned' and 'carrier_name'\n",
    "unique_census_carrier_names = pd.Series(df['census_carrier_name_cleaned'].unique()).dropna()\n",
    "unique_ideon_carrier_names = pd.Series(df['ideon_carrier_name'].unique()).dropna()\n",
    "all_unique_carrier_names = pd.concat([unique_census_carrier_names, unique_ideon_carrier_names]).unique()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(all_unique_carrier_names)\n",
    "\n",
    "# Transform 'census_carrier_name_cleaned' and 'ideon_carrier_name' to embeddings\n",
    "df['census_carrier_name_text_embedding'] = list(tfidf_vectorizer.transform(df['census_carrier_name_cleaned']).toarray())\n",
    "df['ideon_carrier_name_text_embedding'] = list(tfidf_vectorizer.transform(df['ideon_carrier_name']).toarray())\n",
    "\n",
    "# 3. Calculate cosine similarity between 'census_carrier_name_cleaned' and 'carrier_name' text embeddings\n",
    "cosine_similarities = cosine_similarity(tfidf_vectorizer.transform(df['census_carrier_name_cleaned']), tfidf_vectorizer.transform(df['ideon_carrier_name']))\n",
    "df['carrier_name_cosine_similarity'] = [cosine_similarities[i][i] for i in range(len(df))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan Level ['platinum','gold','silver','bronze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract 'plan_level' from 'census_plan_admin_name_cleaned'\n",
    "df['census_plan_level'] = df['census_plan_admin_name_cleaned'].str.extract('(gold|silver|platinum|bronze)', flags=re.IGNORECASE, expand=False)\n",
    "\n",
    "# 2. Normalize 'plan_level'\n",
    "df['census_plan_level'] = df['census_plan_level'].str.lower()\n",
    "df['ideon_plan_level'] = df['ideon_plan_level'].replace('expanded_bronze', 'bronze')\n",
    "\n",
    "# 3. Combine unique 'plan_level' values from both columns\n",
    "unique_plan_levels_census = pd.Series(df['census_plan_level'].unique()).dropna()\n",
    "unique_plan_levels_ideon = pd.Series(df['ideon_plan_level'].unique()).dropna()\n",
    "all_unique_plan_levels = pd.concat([unique_plan_levels_census, unique_plan_levels_ideon]).unique()\n",
    "\n",
    "# 4. Create text embeddings for unique 'plan_level' values\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(all_unique_plan_levels)\n",
    "\n",
    "# 5. Transform 'census_plan_level' and 'ideon_plan_level' to embeddings\n",
    "df['census_plan_level_embedding'] = list(tfidf_vectorizer.transform(df['census_plan_level'].fillna('')).toarray())\n",
    "df['ideon_plan_level_embedding'] = list(tfidf_vectorizer.transform(df['ideon_plan_level'].fillna('')).toarray())\n",
    "\n",
    "# 6. Calculate cosine similarity between 'census_plan_level_embedding' and 'ideon_plan_level_embedding'\n",
    "df['plan_level_cosine_similarity'] = df.apply(lambda row: cosine_similarity([row['census_plan_level_embedding']], [row['ideon_plan_level_embedding']])[0][0], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan Name ['ideon_name' and 'census_plan_admin_name_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate length of the name columns\n",
    "df['census_plan_admin_name_cleaned_length'] = df['census_plan_admin_name_cleaned'].apply(len)\n",
    "df['ideon_name_length'] = df['ideon_name'].apply(len)\n",
    "\n",
    "# 2. create text embeddings for the name columns\n",
    "df['plan_names_combined'] = df['census_plan_admin_name_cleaned'] + ' ' + df['ideon_name']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "tfidf_vectorizer.fit(df['plan_names_combined'])\n",
    "\n",
    "# 3. Transform the plan name columns to embeddings\n",
    "df['census_plan_admin_name_cleaned_embedding'] = list(tfidf_vectorizer.transform(df['census_plan_admin_name_cleaned'].fillna('')).toarray())\n",
    "df['ideon_name_embedding'] = list(tfidf_vectorizer.transform(df['ideon_name'].fillna('')).toarray())\n",
    "\n",
    "# 4. Calculate cosine similarity between 'census_plan_level_embedding' and 'ideon_plan_level_embedding'\n",
    "df['plan_name_cosine_similarity'] = df.apply(lambda row: cosine_similarity([row['census_plan_admin_name_cleaned_embedding']], [row['ideon_name_embedding']])[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dat Preparation\n",
    "X = df[[\n",
    "    \"census_carrier_name_length\", \n",
    "    \"ideon_carrier_name_length\", \n",
    "    \"carrier_name_cosine_similarity\", \n",
    "    \"census_plan_level\",\n",
    "    \"ideon_plan_level\",\n",
    "    \"plan_level_cosine_similarity\", \n",
    "    \"census_plan_admin_name_cleaned_length\", \n",
    "    \"ideon_name_length\", \n",
    "    \"plan_name_cosine_similarity\"\n",
    "]]\n",
    "y = df[\"is_match\"]\n",
    "\n",
    "# split the data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# categorical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "\n",
    "# numerical columns\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Preprocessing for categorical data and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ])\n",
    "\n",
    "# Define the pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier()),\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [3, 5, 7, 9],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters found: ', grid.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "SaveModelMetrics(file_path='~/match-plans/data/model_results.csv').save_metrics(\n",
    "    name='model_v1',\n",
    "    description='A v1 model that cleans the carrier_name and plan_admin_name from the census to add in plan_level and carrier_name and then creates text embeddings and computes a similartity score.',\n",
    "    algorithm='XGBoostClassifier',\n",
    "    best_params_grid_search=grid.best_params_,\n",
    "    params=grid.best_estimator_.get_params(),\n",
    "    accuracy_score=accuracy,\n",
    "    precision_score=precision,\n",
    "    recall=recall,\n",
    "    f1_score=f1,\n",
    "    conf_matrix=conf_matrix\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan Type, HDHP / HSA, Levenshtein String Distance, Appendage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model will take the v1 model, and will add some more features around plan type and issuer code\n",
    "\n",
    "1. Feature Engineering pt. 2\n",
    "    * extract the plan type from the plan_admin_name string if available\n",
    "    * convert the plan_type in the Ideon set to PPO, HMO, HDHP\n",
    "    * add in HDHP / HSA from plan_admin_name and the boolean from Ideon dataset\n",
    "2. I want to add in Levenshtein string distance just to see if that feature matters vs. the vector / text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the levenshtein string distance between plan_admin_name_cleaned and ideon_name\n",
    "df['plan_name_levenshtein_distance'] = df.apply(lambda row: lev.distance(row['census_plan_admin_name_cleaned'], row['ideon_name']), axis=1)\n",
    "df['carrier_name_levenshtein_distance'] = df.apply(lambda row: lev.distance(row['census_carrier_name_cleaned'], row['ideon_carrier_name']), axis=1)\n",
    "\n",
    "# check if the census_plan_admin_name_cleaned has HSA or HDHP, with case set to false\n",
    "df['census_hsa_hdhp'] = df['census_plan_admin_name_cleaned'].str.contains('HSA|HDHP', case=False)\n",
    "\n",
    "# check for plan_type in the census_plan_admin_name_cleaned column, if it is in there, figure out which type (PPO or HMO), and then add that to the census_plan_type column\n",
    "def determine_plan_type(name: str):\n",
    "    lower_name = name.lower()\n",
    "    if 'ppo' in lower_name or 'pos' in lower_name:\n",
    "        return 'PPO'\n",
    "    elif 'hmo' in lower_name:\n",
    "        return 'HMO'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['census_plan_type'] = df['census_plan_admin_name_cleaned'].apply(determine_plan_type)\n",
    "    \n",
    "# normalize ideon_plan_type column\n",
    "df['ideon_plan_type'] = df['ideon_plan_type'].replace({'POS': 'PPO', 'EPO': 'PPO'})\n",
    "\n",
    "# issuer code - if there is an issuer code in the census_plan_admin_name_cleaned, then lets extract that and add it to a column. then, lets do levenshtein string distance to that issuer_code and also cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dat Preparation\n",
    "X = df[[\n",
    "    \"census_carrier_name_length\", \n",
    "    \"ideon_carrier_name_length\", \n",
    "    \"carrier_name_cosine_similarity\",\n",
    "    \"census_hsa_hdhp\",\n",
    "    \"ideon_hsa_hdhp\",\n",
    "    \"census_plan_type\",\n",
    "    \"ideon_plan_type\",\n",
    "    \"ideon_plan_level\",\n",
    "    \"census_plan_level\",\n",
    "    \"plan_level_cosine_similarity\", \n",
    "    \"census_plan_admin_name_cleaned_length\", \n",
    "    \"ideon_name_length\", \n",
    "    \"plan_name_cosine_similarity\",\n",
    "    \"plan_name_levenshtein_distance\",\n",
    "    \"carrier_name_levenshtein_distance\"\n",
    "]]\n",
    "y = df[\"is_match\"]\n",
    "\n",
    "# split the data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# categorical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "\n",
    "# numerical columns\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Preprocessing for categorical data and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ])\n",
    "\n",
    "# Define the pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier()),\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [3, 5, 7, 9],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters found: ', grid.best_params_)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "SaveModelMetrics(file_path='~/match-plans/data/model_results.csv').save_metrics(\n",
    "    name='model_v2.4',\n",
    "    description='A v2 model that uses the v1 model and adds on levenshtein distance between plan names and carrier names, adds in HDHP/HSA, and plan_type. Removed expanded bronze from the ideon set (replace with bronze)',\n",
    "    algorithm='XGBoostClassifier',\n",
    "    best_params_grid_search=grid.best_params_,\n",
    "    params=grid.best_estimator_.get_params(),\n",
    "    accuracy_score=accuracy,\n",
    "    precision_score=precision,\n",
    "    recall=recall,\n",
    "    f1_score=f1,\n",
    "    conf_matrix=conf_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the true labels, predicted labels, and the test data\n",
    "results = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_pred,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['y_true'] != results['y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[6508:6509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Get the feature importances from the fitted model\n",
    "feature_importances = best_model.named_steps['model'].feature_importances_\n",
    "\n",
    "# Get the feature names after preprocessing\n",
    "# For numerical features, it's straightforward\n",
    "feature_names = numerical_cols\n",
    "\n",
    "# For categorical features, we need to transform the names to match the one-hot encoding\n",
    "ohe_categories = best_model.named_steps['preprocessor'].named_transformers_['cat'].categories_\n",
    "\n",
    "# Flatten the list of categories per categorical feature\n",
    "flat_categories = [item for sublist in ohe_categories for item in sublist]\n",
    "\n",
    "# Combine numerical and categorical feature names\n",
    "all_feature_names = feature_names + flat_categories\n",
    "\n",
    "# Now we can plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(all_feature_names)), feature_importances, align='center')\n",
    "plt.yticks(range(len(all_feature_names)), all_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance from XGBoost Model')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "* I'd love to find a way to handle the classification of Grandfathered / Non CA plans... isn't that a thing I can teach the model to handle?\n",
    "* In other words, it would be no match for what that plan looks like and the reason would be Grandfathered? I feel like that is something I can program a model to understand, espeically one like XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f44cbdfb2efbc0cea1434bb138a03e1afe958e8794e0d0448957ca4693084e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
